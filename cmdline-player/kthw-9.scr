.MD >  **Kubernetes the Hard Way using My Own Kind**
.MD > 
.MD > View a [screencast and transcript](/cmdline-player/kthw-9.md)
screencast delay 10
screencast clear
screencast paste
# ---------------------------------------------------------
screencast paste
# Kubernetes the Hard Way - using `mokctl` from My Own Kind
screencast paste
# ---------------------------------------------------------
screencast paste
# 09-bootstrapping-kubernetes-workers
screencast paste
# Configure and start the kubernetes workers

.MD # Bootstrapping the Kubernetes Worker Nodes
.MD 
.MD In this lab you will bootstrap three Kubernetes worker nodes. The following components will be installed on each node: [runc](https://github.com/opencontainers/runc), [container networking plugins](https://github.com/containernetworking/cni), [containerd](https://github.com/containerd/containerd), [kubelet](https://kubernetes.io/docs/admin/kubelet), and [kube-proxy](https://kubernetes.io/docs/concepts/cluster-administration/proxies).
.MD 
.MD ## Prerequisites
.MD 
.MD The commands in this lab must be run on each worker instance: `kthw-worker-1`, `kthw-worker-2`, and `kthw-worker-3`. Log in to each controller instance using the `mokctl` command. Example:
.MD 
.MD ```
.MD mokctl exec kthw-worker-1
.MD ```
.MD 
.MD ### Running commands in parallel with tmux
.MD 
.MD [tmux](https://github.com/tmux/tmux/wiki) can be used to run commands on multiple compute instances at the same time. See the [Running commands in parallel with tmux](01-prerequisites.md#running-commands-in-parallel-with-tmux) section in the Prerequisites lab.
.MD 
.MD ## Provisioning a Kubernetes Worker Node
.MD 
# Provision the Kubernetes Worker Nodes

screencast prompt %$#
# We will use 'tmux' to log in to three containers and then
# execute the commands in parallel.
screencast delay 18

.MD Use `tmux` to log in to all three worker at the same time:
.MD
.MD ```
screencast subshell
tmux
tmux set status off
screencast prompt %$#
tmux split
tmux split
tmux select-layout even-vertical
tmux select-pane -D
screencast sleep 1
sudo mokctl exec kthw-worker-1
screencast sleep 1
^aj
screencast sleep 1
sudo mokctl exec kthw-worker-2
screencast sleep 1
^aj
screencast sleep 1
tmux select-layout tiled
tmux resize-pane -y 25
sudo mokctl exec kthw-worker-3
# syncing screens
screencast sleep 1
^a^x
screencast sleep 1
# Panes are now synced!
# Clearing the screen
clear
.MD ```
.MD
.MD `mokctl` installed a few kubernetes services ready for set up.
.MD
.MD Ensure all existing kubernetes services are deleted:
.MD
.MD ```
# Remove the existing k8s services:
screencast paste
yum -y remove kubelet kubeadm cri-o cri-tools runc criu
.MD ```
.MD
.MD Change to root's home directory, where the certs are:
.MD
.MD ```
cd # <- All our certs are in root's home
.MD ```
.MD
.MD Install the OS dependencies:
.MD 
.MD ```
# Install OS dependencies
screencast paste begin
{
  yum -y install socat conntrack ipset wget
}
screencast paste end
.MD ```
.MD 
.MD > The socat binary enables support for the `kubectl port-forward` command.
.MD 
.MD ### Disable Swap
.MD 
.MD By default the kubelet will fail to start if [swap](https://help.ubuntu.com/community/SwapFaq) is enabled. It is [recommended](https://github.com/kubernetes/kubernetes/issues/7294) that swap be disabled to ensure Kubernetes can provide proper resource allocation and quality of service.
.MD 
.MD Verify if swap is enabled:
.MD 
.MD ```
# Is swap on?
swapon --show
# Yes, and so it should be for a laptop.
.MD ```
.MD 
.MD If output is empty then swap is not enabled. If swap is enabled run the following command to disable swap immediately:
.MD 
.MD ```
# `mokctl` uses a kubeadm configuration file to get components to ignore swap.
# For this lab the following lines will trick kubernetes into
# thinking that swap is off instead:
touch /swapoff
mount --bind /swapoff /proc/swaps
# We don't want to turn swap off on our laptop.
.MD ```
.MD 
.MD Verify again if swap is enabled:
.MD 
.MD ```
# Is swap on?
swapon --show
# Seems to be off now :)
.MD ```
.MD 
.MD Swap should now return no output, meaning, it's off.
.MD 
.MD > To ensure swap remains off after reboot consult your Linux distro documentation.
.MD 
.MD ### Download and Install Worker Binaries
.MD 
.MD ```
# Download the worker binaries
screencast waitforsilence
screencast paste begin
wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.15.0/crictl-v1.15.0-linux-amd64.tar.gz \
  https://github.com/opencontainers/runc/releases/download/v1.0.0-rc8/runc.amd64 \
  https://github.com/containernetworking/plugins/releases/download/v0.8.2/cni-plugins-linux-amd64-v0.8.2.tgz \
  https://github.com/containerd/containerd/releases/download/v1.2.9/containerd-1.2.9.linux-amd64.tar.gz \
  https://storage.googleapis.com/kubernetes-release/release/v1.15.3/bin/linux/amd64/kubectl \
  https://storage.googleapis.com/kubernetes-release/release/v1.15.3/bin/linux/amd64/kube-proxy \
  https://storage.googleapis.com/kubernetes-release/release/v1.15.3/bin/linux/amd64/kubelet
screencast paste end
.MD ```
.MD 
.MD Create the installation directories:
.MD 
.MD ```
# Create the installation directories:
screencast paste begin
mkdir -p \
  /etc/cni/net.d \
  /opt/cni/bin \
  /var/lib/kubelet \
  /var/lib/kube-proxy \
  /var/lib/kubernetes \
  /var/run/kubernetes
screencast paste end
.MD ```
.MD 
.MD Install the worker binaries:
.MD 
.MD ```
# Install the worker binaries:
screencast paste begin
{
  mkdir containerd
  tar -xvf crictl-v1.15.0-linux-amd64.tar.gz
  tar -xvf containerd-1.2.9.linux-amd64.tar.gz -C containerd
  tar -xvf cni-plugins-linux-amd64-v0.8.2.tgz -C /opt/cni/bin/
  mv runc.amd64 runc
  chmod +x crictl kubectl kube-proxy kubelet runc 
  mv -f crictl kubectl kube-proxy kubelet runc /usr/local/bin/
  mv -f containerd/bin/* /bin/
}
screencast paste end
.MD ```
.MD 
.MD ### Configure CNI Networking
.MD 
.MD Work out the Pod CIDR range for the current compute instance.
.MD 
.MD We will use the following subnets from the 10.200.0.0/16 range:
.MD
.MD *  10.200.1.0/24 for kthw-worker-1
.MD *  10.200.2.0/24 for kthw-worker-2
.MD *  10.200.3.0/24 for kthw-worker-3
.MD
.MD ```
# Work out the pod subnet for this host:
screencast paste
POD_CIDR="10.200.$(hostname -s | grep -o '.$').0/24"
echo $POD_CIDR
.MD ```
.MD 
.MD Create the `bridge` network configuration file:
.MD 
.MD ```
# Write the CNI bridge configuration:
screencast paste begin
cat <<EOF | tee /etc/cni/net.d/10-bridge.conf
{
    "cniVersion": "0.3.1",
    "name": "bridge",
    "type": "bridge",
    "bridge": "cnio0",
    "isGateway": true,
    "ipMasq": true,
    "ipam": {
        "type": "host-local",
        "ranges": [
          [{"subnet": "${POD_CIDR}"}]
        ],
        "routes": [{"dst": "0.0.0.0/0"}]
    }
}
EOF
screencast paste end
.MD ```
.MD 
.MD Create the `loopback` network configuration file:
.MD 
.MD ```
# Write the CNI loopback device config:
screencast paste begin
cat <<EOF | tee /etc/cni/net.d/99-loopback.conf
{
    "cniVersion": "0.3.1",
    "name": "lo",
    "type": "loopback"
}
EOF
screencast paste end
.MD ```
.MD 
.MD ### Configure containerd
.MD 
.MD See also: [Docker Storage Drivers](https://docs.docker.com/storage/storagedriver/select-storage-driver/).
.MD
.MD Create the `containerd` configuration file:
.MD 
.MD ```
# Containerd config:
screencast paste
mkdir -p /etc/containerd/
.MD ```
.MD 
.MD ```
screencast paste begin
containerd config default | sed 's/overlayfs/native/' >/etc/containerd/config.toml
screencast paste end
.MD ```
.MD 
.MD Create the `containerd.service` systemd unit file:
.MD 
.MD ```
# Create the systemd unit file:
screencast paste begin
cat <<EOF | tee /etc/systemd/system/containerd.service
[Unit]
Description=containerd container runtime
Documentation=https://containerd.io
After=network.target

[Service]
ExecStartPre=/sbin/modprobe overlay
ExecStart=/bin/containerd
Restart=always
RestartSec=5
Delegate=yes
KillMode=process
OOMScoreAdjust=-999
LimitNOFILE=1048576
LimitNPROC=infinity
LimitCORE=infinity

[Install]
WantedBy=multi-user.target
EOF
screencast paste end
.MD ```
.MD 
.MD ### Configure the Kubelet
.MD 
.MD ```
# Configure the kubelet:
screencast paste begin
{
  mv ${HOSTNAME}-key.pem ${HOSTNAME}.pem /var/lib/kubelet/
  mv ${HOSTNAME}.kubeconfig /var/lib/kubelet/kubeconfig
  mv ca.pem /var/lib/kubernetes/
}
screencast paste end
.MD ```
.MD 
.MD Create the `kubelet-config.yaml` configuration file:
.MD 
.MD ```
# Kubelet config:
screencast paste begin
cat <<EOF | tee /var/lib/kubelet/kubelet-config.yaml
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: false
  webhook:
    enabled: true
  x509:
    clientCAFile: "/var/lib/kubernetes/ca.pem"
authorization:
  mode: Webhook
clusterDomain: "cluster.local"
clusterDNS:
  - "10.32.0.10"
podCIDR: "${POD_CIDR}"
runtimeRequestTimeout: "15m"
tlsCertFile: "/var/lib/kubelet/${HOSTNAME}.pem"
tlsPrivateKeyFile: "/var/lib/kubelet/${HOSTNAME}-key.pem"
EOF
screencast paste end
.MD ```
.MD 
.MD > The `resolvConf` configuration is used to avoid loops when using CoreDNS for service discovery on systems running `systemd-resolved`. 
.MD 
.MD Create the `kubelet.service` systemd unit file:
.MD 
.MD ```
# Create systemd unit file for kubelet:
screencast paste begin
cat <<EOF | tee /etc/systemd/system/kubelet.service
[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes
After=containerd.service
Requires=containerd.service

[Service]
ExecStart=/usr/local/bin/kubelet \\
  --config=/var/lib/kubelet/kubelet-config.yaml \\
  --container-runtime=remote \\
  --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock \\
  --image-pull-progress-deadline=2m \\
  --kubeconfig=/var/lib/kubelet/kubeconfig \\
  --network-plugin=cni \\
  --register-node=true \\
  --v=2
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF
screencast paste end
.MD ```
.MD 
.MD ### Configure the Kubernetes Proxy
.MD 
# Configure the kube-proxy:
.MD ```
screencast paste
mv kube-proxy.kubeconfig /var/lib/kube-proxy/kubeconfig
.MD ```
.MD 
.MD Create the `kube-proxy-config.yaml` configuration file:
.MD 
.MD ```
# Write the kube-proxy-config.yaml file:
screencast paste begin
cat <<EOF | tee /var/lib/kube-proxy/kube-proxy-config.yaml
kind: KubeProxyConfiguration
apiVersion: kubeproxy.config.k8s.io/v1alpha1
clientConnection:
  kubeconfig: "/var/lib/kube-proxy/kubeconfig"
mode: "iptables"
clusterCIDR: "10.200.0.0/16"
EOF
.MD ```
.MD 
.MD Create the `kube-proxy.service` systemd unit file:
.MD 
.MD ```
# Write the systemd unit file for kube-proxy:
screencast paste begin
cat <<EOF | tee /etc/systemd/system/kube-proxy.service
[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kube-proxy \\
  --config=/var/lib/kube-proxy/kube-proxy-config.yaml
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF
screencast paste end
.MD ```
.MD 
.MD ### Start the Worker Services
.MD 
.MD ```
# Start worker services:
screencast paste begin
{
  systemctl daemon-reload
  systemctl enable containerd kubelet kube-proxy
  systemctl start containerd kubelet kube-proxy
}
screencast paste end
.MD ```
.MD 
.MD > Remember to run the above commands on each worker node: `kthw-worker-1`, `kthw-worker-2`, and `kthw-worker-3`.
.MD 
.MD ## Verification
.MD 
.MD > The compute instances created in this tutorial will not have permission to complete this section. Run the following commands from one of the master nodes.
.MD 
.MD Log out of the workers:
.MD
.MD ```
# Log out of the workers:
exit
exit
.MD ```
.MD
.MD Log in to one of the master nodes to run kubectl:
.MD
.MD ```
# And log in to kthw-master-1
screencast paste
sudo mokctl exec kthw-master-1
cd    # <- our admin.kubeconfig is in root's home (/root)
.MD ```
.MD
.MD List the registered Kubernetes nodes:
.MD 
.MD ```
# Verification - list the nodes:
screencast paste
kubectl get nodes --kubeconfig admin.kubeconfig
# It worked!
.MD ```
.MD 
.MD > output
.MD 
.MD ```
.MD NAME            STATUS   ROLES    AGE   VERSION
.MD kthw-worker-1   Ready    <none>   15s   v1.15.3
.MD kthw-worker-2   Ready    <none>   15s   v1.15.3
.MD kthw-worker-3   Ready    <none>   15s   v1.15.3
.MD ```
# Log out of the master container
.MD
.MD Log out of the master container:
.MD
.MD ```
exit
.MD ```
.MD
# All done :)
.MD

# -------------------------------------------
# Next: Configuring kubectl for Remote Access
screencast paste
# -------------------------------------------
.MD Next: [Configuring kubectl for Remote Access](10-configuring-kubectl.md)
